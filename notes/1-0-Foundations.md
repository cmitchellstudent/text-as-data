## Basic Text Operations

0.4/5. **Files**. If we need to, we can review  the basics of loading text from files as well as scraping sites to get files. We can discuss using a shell command like `wget` as well as Python libraries for doing similar things. (It's possible we will cover `BeautifulSoup` here: but we may come back to getting data once we have worked with some provided materials.)

**Further**: [A Short History and Explanation of
GREP](https://www.youtube.com/watch?v=NTfOnGZUZDk).

 identifying and extracting core content, and deconstructing texts into
various constituent parts: paragraphs, sentences, words. We also discuss
what it means to work with a corpus and how to transform and store texts
into a corpus that can be readily accessed and used.

**Method(s)**: Tokenization, Stop lists

**Action(s)**:

### Unit 1 \| getting up to speed

*In this first unit we explore some of the ways that texts can be
quantified using extant corpora. This is a prelude to use developing our own corpora and determining what dimensions we wish to pursue in the units that follow.*

1. [From Files to Texts to Words]()
2. [Multiple Files, Multiple Texts, Multiple Lists of Strings]()



Alphabetizing Texts

[Marty Robbins’ “Big Iron”](https://www.youtube.com/watch?v=-NuX79Ud8zI): [Alphabtized](https://www.youtube.com/watch?v=j_Dyg2Dw5xI).