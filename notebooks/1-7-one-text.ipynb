{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# 1-7 `countvectorizer` with One Text\n",
    "\n",
    "*You Know the One*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# IMPORTS & PARAMETERS\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.rcParams['figure.dpi'] = 300\n",
    "# plt.rcParams[\"figure.figsize\"] = (10,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick note about **countvectorizer**: while it expects a list, that doesn't mean you can't feed it a list with only one item or only one item from a list if you want to explore a single text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>able</th>\n",
       "      <th>aboard</th>\n",
       "      <th>about</th>\n",
       "      <th>above</th>\n",
       "      <th>abrupt</th>\n",
       "      <th>abruptly</th>\n",
       "      <th>absorbed</th>\n",
       "      <th>accent</th>\n",
       "      <th>accustomed</th>\n",
       "      <th>achieved</th>\n",
       "      <th>...</th>\n",
       "      <th>yet</th>\n",
       "      <th>york</th>\n",
       "      <th>you</th>\n",
       "      <th>young</th>\n",
       "      <th>younger</th>\n",
       "      <th>your</th>\n",
       "      <th>yourself</th>\n",
       "      <th>zaroff</th>\n",
       "      <th>zealous</th>\n",
       "      <th>zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>105</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 1918 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   able  aboard  about  above  abrupt  abruptly  absorbed  accent  accustomed  \\\n",
       "0     1       1     18      3       1         1         1       1           1   \n",
       "\n",
       "   achieved  ...  yet  york  you  young  younger  your  yourself  zaroff  \\\n",
       "0         1  ...    2     2  105      4        1    13         1      20   \n",
       "\n",
       "   zealous  zone  \n",
       "0        1     1  \n",
       "\n",
       "[1 rows x 1918 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Our Usual Suspect\n",
    "mdg_string = open('../data/mdg.txt', 'r').read()\n",
    "\n",
    "# Initiate the vectorizer with the default parameters\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Create the matrix\n",
    "X = vectorizer.fit_transform([mdg_string])\n",
    "\n",
    "# Convert to a dataframe\n",
    "mdg = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "# See it\n",
    "mdg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse._csr.csr_matrix"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A couple of things to note about the steps above: after we read the file into a string object (variable) and instantiate the default vectorizer, we feed the string into the vectorizer as a list. A list with only one item, but still a list. Why? Because the vectorizer expects a list of strings. *Try taking the square brackets out above to see what error you get.*\n",
    "\n",
    "The vectorizer outputs an object we are calling `X` above. If you ask Python what type of object `X` is using the `type()` function, it will tell you that it's a `scipy.sparse._csr.csr_matrix`. This is one of those instances where our package management system, `conda`, has done nice work in the background for for us by installing `scipy` when it installed `sci-kit learn`. When I ask `conda` to tell me about `scipy` by simply typing `conda list scipy`, it gives me the following response:\n",
    "```\n",
    "# Name       Version      Build              Channel\n",
    "scipy        1.11.4       py311he0bea55_0    conda-forge\n",
    "```\n",
    "*Nice!*\n",
    "\n",
    "Finally, we convert our `matrix` into a `dataframe` with all our columns labelled. We do this by first converting it to an array and then to a dataframe. If you'd like to see what the array looks like, you can include an intermediate step -- `mdg_array = X.toarray()`. If you enter simply `mdg_array` or `print(mdg_array`, you will see something like this:\n",
    "```\n",
    "[[ 1,  1, 18, ..., 20,  1,  1]]\n",
    "```\n",
    "This reveals an array of one row and many columns. If you want the exact dimensions, or *shape* of the array, any array, you can simply enter `mdg_array.shape` and you get `(1, 1918)`. \n",
    "\n",
    "Vectorizer has a lot of functionality, both in terms of parameters going in and what you can get out. The one you will use the most is getting the names of features, which in most instances in this course will be words. \n",
    "\n",
    "Let's take a closer look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "1918\n",
      "['able' 'aboard' 'about' 'above' 'abrupt' 'abruptly' 'absorbed' 'accent'\n",
      " 'accustomed' 'achieved' 'aching' 'acknowledge' 'acres' 'across'\n",
      " 'actually' 'added' 'adjusted' 'admitted' 'advanced' 'affable']\n"
     ]
    }
   ],
   "source": [
    "# Get the words\n",
    "words = vectorizer.get_feature_names_out()\n",
    "\n",
    "# What kind of object is this?\n",
    "print(type(words))\n",
    "\n",
    "# We're pretty sure we know this, but let's see it again:\n",
    "print(len(words))\n",
    "\n",
    "# And let's see some of those words\n",
    "print(words[0:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have words and we have often they occur in the text. Like before, we can examine the various kinds of occurrences: most, least, various middle ranges:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>he</th>\n",
       "      <td>248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>was</th>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>his</th>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rainsford</th>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>general</th>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0\n",
       "the        512\n",
       "he         248\n",
       "of         172\n",
       "and        164\n",
       "to         148\n",
       "was        140\n",
       "his        137\n",
       "rainsford  134\n",
       "in         108\n",
       "general    106"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pandas' T function transposes a dataframe\n",
    "mdg.T.sort_values(by=0, ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use pandas' column selection feature. Curious to know how often *hunter* occurs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "('hunter', 'hunted', 'hunting')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/370/lib/python3.11/site-packages/pandas/core/indexes/base.py:3791\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3790\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3791\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3792\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: ('hunter', 'hunted', 'hunting')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmdg\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhunter\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhunted\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhunting\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/370/lib/python3.11/site-packages/pandas/core/frame.py:3893\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3891\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3892\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3893\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3895\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/miniconda3/envs/370/lib/python3.11/site-packages/pandas/core/indexes/base.py:3798\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3793\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3794\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3795\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3796\u001b[0m     ):\n\u001b[1;32m   3797\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3798\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3799\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3800\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3801\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3802\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3803\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: ('hunter', 'hunted', 'hunting')"
     ]
    }
   ],
   "source": [
    "mdg['hunter', 'hunted', 'hunting']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we know how often *hunter* occurs in the text: 11 times. If the word hunter occurs 11 times in Shakespeare's _As You Like It_, which is set in the woods, are the two texts likely to have if not the same meaning than overlapping meanings?\n",
    "\n",
    "While the possibility of some overlap is intriguing, how often a word appears in a text doesn't really tell us that much about its possible significance. There is a way, however, to normalize counts across texts such that we can compare one text to another or, if we use reference corpora, at least see if a word occurs more or less frequently than it does on average in other texts of this type or period (or some other boundary of our choosing -- this text analytics business is all about choosing the context which interests you). \n",
    "\n",
    "The answer is obvious: divide the count of a particular word (token) by the total number of words (tokens) in a text. (By including *tokens*, I want to remind you not to rule out punctuation and other kinds of non-word forms.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the relative frequency of our words we might:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7609\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add up all the counts to get the total word count\n",
    "mdg.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>able</th>\n",
       "      <th>aboard</th>\n",
       "      <th>about</th>\n",
       "      <th>above</th>\n",
       "      <th>abrupt</th>\n",
       "      <th>abruptly</th>\n",
       "      <th>absorbed</th>\n",
       "      <th>accent</th>\n",
       "      <th>accustomed</th>\n",
       "      <th>achieved</th>\n",
       "      <th>...</th>\n",
       "      <th>yet</th>\n",
       "      <th>york</th>\n",
       "      <th>you</th>\n",
       "      <th>young</th>\n",
       "      <th>younger</th>\n",
       "      <th>your</th>\n",
       "      <th>yourself</th>\n",
       "      <th>zaroff</th>\n",
       "      <th>zealous</th>\n",
       "      <th>zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.002366</td>\n",
       "      <td>0.000394</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000263</td>\n",
       "      <td>0.000263</td>\n",
       "      <td>0.013799</td>\n",
       "      <td>0.000526</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.001709</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.002628</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.000131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 1918 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       able    aboard     about     above    abrupt  abruptly  absorbed  \\\n",
       "0  0.000131  0.000131  0.002366  0.000394  0.000131  0.000131  0.000131   \n",
       "\n",
       "     accent  accustomed  achieved  ...       yet      york       you  \\\n",
       "0  0.000131    0.000131  0.000131  ...  0.000263  0.000263  0.013799   \n",
       "\n",
       "      young   younger      your  yourself    zaroff   zealous      zone  \n",
       "0  0.000526  0.000131  0.001709  0.000131  0.002628  0.000131  0.000131  \n",
       "\n",
       "[1 rows x 1918 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Then divide all the columns by that number\n",
    "mdg_rf = mdg.div(7609)\n",
    "mdg_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That works, but it's not very repeatable. At some point we are going to have more than one text, and thus more than one row. Why not store the total word count for each row in a column in that row? We can then have pandas divide the rest of the columns by the new column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7609\n",
       "Name: sum, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store the total word count in a new column\n",
    "mdg['sum'] = mdg.sum(axis=1)\n",
    "mdg['sum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>able</th>\n",
       "      <th>aboard</th>\n",
       "      <th>about</th>\n",
       "      <th>above</th>\n",
       "      <th>abrupt</th>\n",
       "      <th>abruptly</th>\n",
       "      <th>absorbed</th>\n",
       "      <th>accent</th>\n",
       "      <th>accustomed</th>\n",
       "      <th>achieved</th>\n",
       "      <th>...</th>\n",
       "      <th>yet</th>\n",
       "      <th>york</th>\n",
       "      <th>you</th>\n",
       "      <th>young</th>\n",
       "      <th>younger</th>\n",
       "      <th>your</th>\n",
       "      <th>yourself</th>\n",
       "      <th>zaroff</th>\n",
       "      <th>zealous</th>\n",
       "      <th>zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.002366</td>\n",
       "      <td>0.000394</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000263</td>\n",
       "      <td>0.000263</td>\n",
       "      <td>0.013799</td>\n",
       "      <td>0.000526</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.001709</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.002628</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.000131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 1918 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       able    aboard     about     above    abrupt  abruptly  absorbed  \\\n",
       "0  0.000131  0.000131  0.002366  0.000394  0.000131  0.000131  0.000131   \n",
       "\n",
       "     accent  accustomed  achieved  ...       yet      york       you  \\\n",
       "0  0.000131    0.000131  0.000131  ...  0.000263  0.000263  0.013799   \n",
       "\n",
       "      young   younger      your  yourself    zaroff   zealous      zone  \n",
       "0  0.000526  0.000131  0.001709  0.000131  0.002628  0.000131  0.000131  \n",
       "\n",
       "[1 rows x 1918 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now divide the columns by that sum\n",
    "# Save the result to a new dataframe tagged as rf for relative frequency\n",
    "mdg_rf = mdg.loc[:, mdg.columns != \"sum\"].div(mdg[\"sum\"], axis=0)\n",
    "mdg_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is harder to read than it should be, but let's try to break it down:\n",
    "\n",
    "`mdg.loc` allows us to access a group of rows and columns by label(s) or a boolean array (more on this later). See [documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html).\n",
    "\n",
    "`[:, mdg.columns != \"sum\"]` tells pandas we want all the column (`:`) except (`!=`) the `sum` column -- we could make this simply `[:]` which is the Python slice notation for \"all the things\" but that would leave the sum column as 1 and throw away useful information. (What if, for example, we wanted to reverse this process and get the original counts back later and all we had was this dataframe?)\n",
    "\n",
    "`.div()` divide by the contents of the parentheses. (Above it was a number, here it is a column, `mdg[\"sum\"]`.\n",
    "\n",
    "`axis=0`: do this by column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "As I have noted multiple times, there are plenty of things we do because that is simply the convention. With that noted, it's important to remember that <b><code>axis=0</code></b> is column-wise: sum or average or whatever all the values in a column; <b><code>axis=1</code></b> is row-wise: perform an operation for each row.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With that in mind, you can perform the same operation as above in a very short line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>able</th>\n",
       "      <th>aboard</th>\n",
       "      <th>about</th>\n",
       "      <th>above</th>\n",
       "      <th>abrupt</th>\n",
       "      <th>abruptly</th>\n",
       "      <th>absorbed</th>\n",
       "      <th>accent</th>\n",
       "      <th>accustomed</th>\n",
       "      <th>achieved</th>\n",
       "      <th>...</th>\n",
       "      <th>yet</th>\n",
       "      <th>york</th>\n",
       "      <th>you</th>\n",
       "      <th>young</th>\n",
       "      <th>younger</th>\n",
       "      <th>your</th>\n",
       "      <th>yourself</th>\n",
       "      <th>zaroff</th>\n",
       "      <th>zealous</th>\n",
       "      <th>zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.002366</td>\n",
       "      <td>0.000394</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000263</td>\n",
       "      <td>0.000263</td>\n",
       "      <td>0.013799</td>\n",
       "      <td>0.000526</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.001709</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.002628</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.000131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 1918 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       able    aboard     about     above    abrupt  abruptly  absorbed  \\\n",
       "0  0.000131  0.000131  0.002366  0.000394  0.000131  0.000131  0.000131   \n",
       "\n",
       "     accent  accustomed  achieved  ...       yet      york       you  \\\n",
       "0  0.000131    0.000131  0.000131  ...  0.000263  0.000263  0.013799   \n",
       "\n",
       "      young   younger      your  yourself    zaroff   zealous      zone  \n",
       "0  0.000526  0.000131  0.001709  0.000131  0.002628  0.000131  0.000131  \n",
       "\n",
       "[1 rows x 1918 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the sum of all the values by row \n",
    "# and then divide all the values by coumn\n",
    "# (remember to read inside out)\n",
    "mdg_rf2 = mdg.div(mdg.sum(axis=1), axis=0)\n",
    "\n",
    "# And, yes, we created ANOTHER dataframe\n",
    "mdg_rf2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As I worked on this code, I used the following code in a cell all by itself so that I could reset the sums. (Otherwise you keep adding to sum column, giving you a bigger word count and even smaller relative frequencies.)\n",
    "```python\n",
    "mdg.drop(['sum'], axis=1, inplace=True)\n",
    "```\n",
    "This is a simple command that lets you drop a column in place. (Bookmark this. It's handy.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, now we have relative frequencies. What can we do with that? \n",
    "\n",
    "First, as noted above, it's the better way to compare texts. Those texts could be in your own corpus, in an established corpus, or a large (and wonky) corpus like Google's [Books Ngram Viewer](https://books.google.com/ngrams/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we go look at the relative frequency for \"hunter\" in the American English corpus of the Ngram Viewer...\n",
    "\n",
    "![](../assets/1-5-3-ngram-hunter.png)\n",
    "\n",
    "We can compare that number against the one for our text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.001446\n",
       "Name: hunter, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdg_rf['hunter']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And if we divide that number by the Google Ngram number we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.5437311371676374"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.001446 / 0.0004080445"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's not clear if Google actually means that as a percentage, if so, we need to by one hundred?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.035437311371676376"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.001446 / 0.0004080445) / 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I find it much easier to believe that \"The Most Dangerous Game\" features the word \"hunter\" three and a half times as often as most texts than it does only three-hundredths as often. Poor interface on Google's part?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another corpus worth exploring is the [Corpus of Contemporary American English (COCA)](https://www.english-corpora.org/coca/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
